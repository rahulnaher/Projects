import xgboost as xgb
import pandas as pd
from sklearn.metrics import mean_absolute_error

# Read in the sales data
sales_data = pd.read_csv("sales_data.csv")

# Filter the data to include only rows where the 'Particulars' column contains 'Silver'
sales_data = sales_data.loc[sales_data['Particulars'].str.contains("Silver")]

# Create one-hot encoded columns for the 'Date' and 'Particulars' columns
sales_data = pd.get_dummies(sales_data, columns=['Date', 'Particulars'])

# Split the data into training and test sets
train_data = sales_data.sample(frac=0.8, random_state=1)
test_data = sales_data.drop(train_data.index)

# Define the features and target
X_train = train_data.drop(columns=["Volume", "Outlet"])
y_train = train_data["Volume"]
X_test = test_data.drop(columns=["Volume", "Outlet"])
y_test = test_data["Volume"]

# Create the XGBoost model
xgb_model = xgb.XGBRegressor(n_estimators=1000, learning_rate=0.05)

# Fit the model to the training data
xgb_model.fit(X_train, y_train)

# Make predictions on the test data
predictions = xgb_model.predict(X_test)

# Print the model's performance on the test data
print("Mean Absolute Error: ", mean_absolute_error(predictions, y_test))
